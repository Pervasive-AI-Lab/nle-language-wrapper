{
  "algo": "APPO",
  "env": "nle_language_env",
  "experiment": "nle_language_agent",
  "experiments_root": null,
  "help": false,
  "train_dir": "./train_dir",
  "device": "gpu",
  "seed": null,
  "save_every_sec": 120,
  "keep_checkpoints": 3,
  "save_milestones_sec": -1,
  "stats_avg": 100,
  "learning_rate": 0.0001,
  "train_for_env_steps": 10000000000,
  "train_for_seconds": 10000000000,
  "obs_subtract_mean": 0.0,
  "obs_scale": 1.0,
  "gamma": 0.99,
  "reward_scale": 0.1,
  "reward_clip": 10.0,
  "encoder_type": "conv",
  "encoder_subtype": "convnet_simple",
  "encoder_custom": "nle_language_transformer_encoder",
  "encoder_extra_fc_layers": 1,
  "hidden_size": 512,
  "nonlinearity": "elu",
  "policy_initialization": "orthogonal",
  "policy_init_gain": 1.0,
  "actor_critic_share_weights": true,
  "use_spectral_norm": false,
  "adaptive_stddev": true,
  "initial_stddev": 1.0,
  "experiment_summaries_interval": 20,
  "adam_eps": 1e-06,
  "adam_beta1": 0.9,
  "adam_beta2": 0.999,
  "gae_lambda": 0.95,
  "rollout": 32,
  "num_workers": 8,
  "recurrence": 32,
  "use_rnn": true,
  "rnn_type": "gru",
  "rnn_num_layers": 1,
  "ppo_clip_ratio": 0.1,
  "ppo_clip_value": 1.0,
  "batch_size": 2048,
  "num_batches_per_iteration": 1,
  "ppo_epochs": 1,
  "num_minibatches_to_accumulate": -1,
  "max_grad_norm": 4.0,
  "exploration_loss_coeff": 0.003,
  "value_loss_coeff": 0.5,
  "kl_loss_coeff": 0.0,
  "exploration_loss": "entropy",
  "num_envs_per_worker": 24,
  "worker_num_splits": 2,
  "num_policies": 1,
  "policy_workers_per_policy": 1,
  "max_policy_lag": 10000,
  "traj_buffers_excess_ratio": 1.3,
  "decorrelate_experience_max_seconds": 10,
  "decorrelate_envs_on_one_worker": true,
  "with_vtrace": true,
  "vtrace_rho": 1.0,
  "vtrace_c": 1.0,
  "set_workers_cpu_affinity": true,
  "force_envs_single_thread": true,
  "reset_timeout_seconds": 120,
  "default_niceness": 0,
  "train_in_background_thread": true,
  "learner_main_loop_num_cores": 1,
  "actor_worker_gpus": [],
  "with_pbt": false,
  "pbt_mix_policies_in_one_env": true,
  "pbt_period_env_steps": 5000000,
  "pbt_start_mutation": 20000000,
  "pbt_replace_fraction": 0.3,
  "pbt_mutation_rate": 0.15,
  "pbt_replace_reward_gap": 0.1,
  "pbt_replace_reward_gap_absolute": 1e-06,
  "pbt_optimize_batch_size": false,
  "pbt_optimize_gamma": false,
  "pbt_target_objective": "true_reward",
  "pbt_perturb_min": 1.05,
  "pbt_perturb_max": 1.5,
  "use_cpc": false,
  "cpc_forward_steps": 8,
  "cpc_time_subsample": 6,
  "cpc_forward_subsample": 2,
  "with_wandb": false,
  "wandb_user": null,
  "wandb_project": "sample_factory",
  "wandb_group": null,
  "wandb_job_type": "SF",
  "wandb_tags": [],
  "benchmark": false,
  "sampler_only": false,
  "env_frameskip": null,
  "env_framestack": 4,
  "pixel_format": "CHW",
  "nle_env_name": "NetHackChallenge-v0",
  "transformer_hidden_size": 64,
  "transformer_hidden_layers": 2,
  "transformer_attention_heads": 2,
  "max_token_length": 256,
  "command_line": "--env nle_language_env --encoder_custom nle_language_transformer_encoder --experiment nle_language_agent --algo APPO --batch_size 2048 --num_envs_per_worker 24 --num_workers 8 --reward_scale 0.1",
  "cli_args": {
    "algo": "APPO",
    "env": "nle_language_env",
    "experiment": "nle_language_agent",
    "reward_scale": 0.1,
    "encoder_custom": "nle_language_transformer_encoder",
    "num_workers": 8,
    "batch_size": 2048,
    "num_envs_per_worker": 24
  },
  "git_hash": "a3ecf3af0ffd0267d98f64d91504606f0a7898b7",
  "git_repo_name": "git@github.com:ngoodger/nle-language-wrapper.git"
}
